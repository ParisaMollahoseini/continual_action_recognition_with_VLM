%مراجع خود را در این قسمت وارد کنید.
% دستوری برای کوچک کردن اندازه فونت‌ها 
%یک مثال را در زیر می‌بینید.

@article{1,
    title={A Comprehensive Survey of Continual Learning: Theory, Method and Application}, 
      author={Liyuan Wang and Xingxing Zhang and Hang Su and Jun Zhu},
      year={2024},
      eprint={2302.00487},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.00487},
        journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}
}
@article{2,
title = {Online continual learning in image classification: An empirical survey},
journal = {Neurocomputing},
volume = {469},
pages = {28-51},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014995},
author = {Zheda Mai and Ruiwen Li and Jihwan Jeong and David Quispe and Hyunwoo Kim and Scott Sanner},
}
@misc{3,
      title={Three scenarios for continual learning}, 
      author={Gido M. van de Ven and Andreas S. Tolias},
      year={2019},
      eprint={1904.07734},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1904.07734}, 
}
@ARTICLE{4,
author={Churamani, Nikhil and Kara, Ozgur and Gunes, Hatice},
journal={ IEEE Transactions on Affective Computing },
title={{ Domain-Incremental Continual Learning for Mitigating Bias in Facial Expression and Action Unit Recognition }},
year={2023},
volume={14},
number={04},
ISSN={1949-3045},
pages={3191-3206},
doi={10.1109/TAFFC.2022.3181033},
url = {https://doi.ieeecomputersociety.org/10.1109/TAFFC.2022.3181033},
publisher={IEEE Computer Society},
address={Los Alamitos, CA, USA},
month=oct}
@INPROCEEDINGS{5,
  author={Ma, Jiawei and Tao, Xiaoyu and Ma, Jianxing and Hong, Xiaopeng and Gong, Yihong},
  booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, 
  title={Class Incremental Learning for Video Action Classification}, 
  year={2021},
  volume={},
  number={},
  pages={504-508},
  keywords={Manifolds;Conferences;Neurons;Machine learning;Feature extraction;Object recognition;Task analysis;Class Incremental Learning;Video action classification;Grow When Required network},
  doi={10.1109/ICIP42928.2021.9506788}}
@INPROCEEDINGS{6,
  author={Park, Jaeyoo and Kang, Minsoo and Han, Bohyung},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Class-Incremental Learning for Action Recognition in Videos}, 
  year={2021},
  volume={},
  number={},
  pages={13678-13687},
  keywords={Learning systems;Computer vision;Image recognition;Benchmark testing;Linear programming;Task analysis;Standards;Action and behavior recognition;Video analysis and understanding},
  doi={10.1109/ICCV48922.2021.01344}}

@article{7,
doi={10.1073/pnas.1611835114},
author = {James Kirkpatrick  and Razvan Pascanu  and Neil Rabinowitz  and Joel Veness  and Guillaume Desjardins  and Andrei A. Rusu  and Kieran Milan  and John Quan  and Tiago Ramalho  and Agnieszka Grabska-Barwinska  and Demis Hassabis  and Claudia Clopath  and Dharshan Kumaran  and Raia Hadsell },
title = {Overcoming catastrophic forgetting in neural networks},
journal = {Proceedings of the National Academy of Sciences},
volume = {114},
number = {13},
pages = {3521-3526},
year = {2017},
doi = {10.1073/pnas.1611835114},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1611835114},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1611835114}
}
@article{8,
  title={Learning without Forgetting},
  author={Zhizhong Li and Derek Hoiem},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2016},
  volume={40},
  pages={2935-2947},
  url={https://api.semanticscholar.org/CorpusID:4853851}
}
@inproceedings{9,
 author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Continual Learning with Deep Generative Replay},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/0efbe98067c6c73dba1250d2beaa81f9-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{10,
  title={Efficient Lifelong Learning with A-GEM},
  author={Arslan Chaudhry and Marc'Aurelio Ranzato and Marcus Rohrbach and Mohamed Elhoseiny},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.00420},
  url={https://api.semanticscholar.org/CorpusID:54443381}
}

@INPROCEEDINGS{11,
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={iCaRL: Incremental Classifier and Representation Learning}, 
  year={2017},
  volume={},
  number={},
  pages={5533-5542},
  keywords={Training;Training data;Prototypes;Feature extraction;Memory management;Classification algorithms;Computer vision},
  doi={10.1109/CVPR.2017.587}}

@article{12,
  title={Online Continual Learning with Maximally Interfered Retrieval},
  author={Rahaf Aljundi and Lucas Caccia and Eugene Belilovsky and Massimo Caccia and Min Lin and Laurent Charlin and Tinne Tuytelaars},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.04742},
  url={https://api.semanticscholar.org/CorpusID:199552250}
}
@article{13,
  author={Minhas, Rashid and Mohammed, Abdul Adeel and Wu, Q. M. Jonathan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Incremental Learning in Human Action Recognition Based on Snippets}, 
  year={2012},
  volume={22},
  number={11},
  pages={1529-1541},
  keywords={Training;Feature extraction;Target tracking;Histograms;Training;Shape;Action recognition;analytic learning;extreme learning machine;incremental learning;snippets},
  doi={10.1109/TCSVT.2011.2177182}}

@INPROCEEDINGS{14,
  author={Li, Tianjiao and Ke, Qiuhong and Rahmani, Hossein and Ho, Rui En and Ding, Henghui and Liu, Jun},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Else-Net: Elastic Semantic Network for Continual Action Recognition from Skeleton Data}, 
  year={2021},
  volume={},
  number={},
  pages={13414-13423},
  keywords={Computer vision;Semantics;Skeleton;Task analysis;Action and behavior recognition;Gestures and body pose},
  doi={10.1109/ICCV48922.2021.01318}}

@ARTICLE{15,
  author={Cheng, Jian and Liu, Haijun and Wang, Feng and Li, Hongsheng and Zhu, Ce},
  journal={IEEE Transactions on Image Processing}, 
  title={Silhouette Analysis for Human Action Recognition Based on Supervised Temporal t-SNE and Incremental Learning}, 
  year={2015},
  volume={24},
  number={10},
  pages={3203-3217},
  keywords={Manifolds;Feature extraction;Learning systems;Probability distribution;Euclidean distance;Training;Mathematical model;Human action recognition;manifold learning;stochastic neighbor embedding;incremental learning;Human action recognition;manifold learning;stochastic neighbor embedding;incremental learning},
  doi={10.1109/TIP.2015.2441634}}

@article{16,
title = {Lifelong learning of human actions with deep neural network self-organization},
journal = {Neural Networks},
volume = {96},
pages = {137-149},
year = {2017},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2017.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0893608017302034},
author = {German I. Parisi and Jun Tani and Cornelius Weber and Stefan Wermter},
}

@ARTICLE{17,
  author={Zhang, Jingyi and Huang, Jiaxing and Jin, Sheng and Lu, Shijian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Vision-Language Models for Vision Tasks: A Survey}, 
  year={2024},
  volume={46},
  number={8},
  pages={5625-5644},
  doi={10.1109/TPAMI.2024.3369699}}

@inproceedings{clip,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={International Conference on Machine Learning},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:231591445}
}
@INPROCEEDINGS{flava,
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={FLAVA: A Foundational Language And Vision Alignment Model}, 
  year={2022},
  volume={},
  number={},
  pages={15617-15629},
  keywords={Computer vision;Analytical models;Computational modeling;Pattern recognition;Task analysis;Vision + language},
  doi={10.1109/CVPR52688.2022.01519}}

@INPROCEEDINGS{glip,
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and Chang, Kai-Wei and Gao, Jianfeng},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Grounded Language-Image Pre-training}, 
  year={2022},
  volume={},
  number={},
  pages={10955-10965},
  keywords={Visualization;Computer vision;Image recognition;Head;Grounding;Object detection;Data models;Deep learning architectures and techniques; Recognition: detection;categorization;retrieval; Representation learning; Transfer/low-shot/long-tail learning; Vision + language},
  doi={10.1109/CVPR52688.2022.01069}}

@article{CoOp,
   title={Learning to Prompt for Vision-Language Models},
   volume={130},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-022-01653-1},
   DOI={10.1007/s11263-022-01653-1},
   number={9},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
   year={2022},
   month=jul, pages={2337–2348} }

@article{actionclip,
	title={ActionCLIP: A New Paradigm for Video Action Recognition},
	author={Mengmeng Wang and Jiazheng Xing and Yong Liu},
	journal={ArXiv},
	year={2021},
	volume={abs/2109.08472},
	url={https://api.semanticscholar.org/CorpusID:237563206}
}

@Article{CLIP-Adapter,
author={Gao, Peng
and Geng, Shijie
and Zhang, Renrui
and Ma, Teli
and Fang, Rongyao
and Zhang, Yongfeng
and Li, Hongsheng
and Qiao, Yu},
title={CLIP-Adapter: Better Vision-Language Models with Feature Adapters},
journal={International Journal of Computer Vision},
year={2024},
month={Feb},
day={01},
volume={132},
number={2},
pages={581-595},
issn={1573-1405},
doi={10.1007/s11263-023-01891-x},
url={https://doi.org/10.1007/s11263-023-01891-x}
}

@INPROCEEDINGS{Wise-FT,
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Robust fine-tuning of zero-shot models}, 
  year={2022},
  volume={},
  number={},
  pages={7949-7961},
  keywords={Computer vision;Computational modeling;Computer network reliability;Transfer learning;Neural networks;Robustness;Data models;Transfer/low-shot/long-tail learning; Machine learning},
  doi={10.1109/CVPR52688.2022.00780}}

@inproceedings{open-vclip,
	title={Open-VCLIP: Transforming CLIP to an Open-vocabulary Video Model via Interpolated Weight Optimization},
	author={Weng, Zejia and Yang, Xitong and Li, Ang and Wu, Zuxuan and Jiang, Yu-Gang},
	booktitle={ICML},
	year={2023}
}

@article{ViLD,
  title={Open-Vocabulary Detection via Vision and Language Knowledge Distillation},
  author={Gu, Xiuye and Lin, Tsung-Yi and Kuo, Weicheng and Cui, Yin},
  journal={arXiv preprint arXiv:2104.13921},
  year={2021}
}

@INPROCEEDINGS{CLIPSeg,
  author={Lüddecke, Timo and Ecker, Alexander},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Image Segmentation Using Text and Image Prompts}, 
  year={2022},
  volume={},
  number={},
  pages={7076-7086},
  doi={10.1109/CVPR52688.2022.00695}}

@article{llm_continual,
author = {Zheng, Junhao and Qiu, Shengjie and Shi, Chengming and Ma, Qianli},
title = {Towards Lifelong Learning of Large Language Models: A Survey},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3716629},
doi = {10.1145/3716629},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {193},
numpages = {35}
}

@INPROCEEDINGS{pivot,
  author={Villa, Andrés and Alcázar, Juan León and Alfarra, Motasem and Alhamoud, Kumail and Hurtado, Julio and Heilbron, Fabian Caba and Soto, Alvaro and Ghanem, Bernard},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={PIVOT: Prompting for Video Continual Learning}, 
  year={2023},
  volume={},
  number={},
  pages={24214-24223},
  doi={10.1109/CVPR52729.2023.02319}}

@InProceedings{diki,
author="Tang, Longxiang
and Tian, Zhuotao
and Li, Kai
and He, Chunming
and Zhou, Hantao
and Zhao, Hengshuang
and Li, Xiu
and Jia, Jiaya",
editor="Leonardis, Ale{\v{s}}
and Ricci, Elisa
and Roth, Stefan
and Russakovsky, Olga
and Sattler, Torsten
and Varol, G{\"u}l",
title="Mind the Interference: Retaining Pre-trained Knowledge in Parameter Efficient Continual Learning of Vision-Language Models",
booktitle="Computer Vision -- ECCV 2024",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="346--365",
isbn="978-3-031-72764-1"
}
@INPROCEEDINGS{l2p,
  author={Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Learning to Prompt for Continual Learning}, 
  year={2022},
  volume={},
  number={},
  pages={139-149},
  doi={10.1109/CVPR52688.2022.00024}}


@inproceedings{replay_clip,
  title={TiC-CLIP: Continual Training of CLIP Models},
  author={Garg, Saurabh and Farajtabar, Mehrdad and Pouransari, Hadi and Vemulapalli, Raviteja and Mehta, Sachin and Tuzel, Oncel and Shankar, Vaishaal and Faghri, Fartash},
  booktitle={The Twelfth International Conference on Learning Representations (ICLR)},
  year={2024},
  url={https://openreview.net/forum?id=TLADT8Wrhn}
}

@inproceedings{clip-poolprompt,
	author = {Wang, Qiang and Du, Junlong and Yan, Ke and Ding, Shouhong},
	title = {Seeing in Flowing: Adapting CLIP for Action Recognition with Motion Prompts Learning},
	year = {2023},
	isbn = {9798400701085},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3581783.3612490},
	doi = {10.1145/3581783.3612490},
	booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
	pages = {5339–5347},
	numpages = {9},
	keywords = {action recognition, clip, motion prompts learning, multimodal},
	location = {Ottawa ON, Canada},
	series = {MM '23}
}

@article{vilt-clip, title={ViLT-CLIP: Video and Language Tuning CLIP with Multimodal Prompt Learning and Scenario-Guided Optimization}, volume={38}, url={https://ojs.aaai.org/index.php/AAAI/article/view/28347}, DOI={10.1609/aaai.v38i6.28347}, 
number={6},
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Wang, Hao and Liu, Fang and Jiao, Licheng and Wang, Jiahao and Hao, Zehua and Li, Shuo and Li, Lingling and Chen, Puhua and Liu, Xu}, year={2024}, month={Mar.}, pages={5390-5400}
}


@INPROCEEDINGS{instance_prompt,
	author={Jung, Dahuin and Han, Dongyoon and Bang, Jihwan and Song, Hwanjun},
	booktitle={2023 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
	title={Generating Instance-level Prompts for Rehearsal-free Continual Learning}, 
	year={2023},
	volume={},
	number={},
	pages={11813-11823},
	keywords={Computer vision;Codes;Scalability;Benchmark testing;Transformers;Market research;Generators},
	doi={10.1109/ICCV51070.2023.01088}}



@article{h-prompts,
	title={Hierarchical Prompts for Rehearsal-free Continual Learning},
	author={Yukun Zuo and Hantao Yao and Lu Yu and Liansheng Zhuang and Changsheng Xu},
	journal={ArXiv},
	year={2024},
	volume={abs/2401.11544},
	url={https://api.semanticscholar.org/CorpusID:267068434}
}


@inproceedings{ovor,
	title={{OVOR}: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning},
	author={Wei-Cheng Huang and Chun-Fu Chen and Hsiang Hsu},
	booktitle={The Twelfth International Conference on Learning Representations},
	year={2024},
	url={https://openreview.net/forum?id=FbuyDzZTPt}
}

@inproceedings{dual-prompt,
	author = {Wang, Zifeng and Zhang, Zizhao and Ebrahimi, Sayna and Sun, Ruoxi and Zhang, Han and Lee, Chen-Yu and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
	title = {DualPrompt: Complementary Prompting for Rehearsal-Free Continual Learning},
	year = {2022},
	isbn = {978-3-031-19808-3},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	url = {https://doi.org/10.1007/978-3-031-19809-0_36},
	doi = {10.1007/978-3-031-19809-0_36},
	booktitle = {Computer Vision – ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXVI},
	pages = {631–648},
	numpages = {18},
	keywords = {Continual learning, Rehearsal-free, Prompt-based learning},
	location = {Tel Aviv, Israel}
}
@InProceedings{starprompt,
	author="Menabue, Martin
	and Frascaroli, Emanuele
	and Boschini, Matteo
	and Sangineto, Enver
	and Bonicelli, Lorenzo
	and Porrello, Angelo
	and Calderara, Simone",
	editor="Leonardis, Ale{\v{s}}
	and Ricci, Elisa
	and Roth, Stefan
	and Russakovsky, Olga
	and Sattler, Torsten
	and Varol, G{\"u}l",
	title="Semantic Residual Prompts for Continual Learning",
	booktitle="Computer Vision -- ECCV 2024",
	year="2025",
	publisher="Springer Nature Switzerland",
	address="Cham",
	pages="1--18",
	isbn="978-3-031-73030-6"
}

@ARTICLE{lora,
	author = {{Wistuba}, Martin and {Teja Sivaprasad}, Prabhu and {Balles}, Lukas and {Zappella}, Giovanni},
	title = "{Choice of PEFT Technique in Continual Learning: Prompt Tuning is Not All You Need}",
	journal = {arXiv e-prints},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	year = 2024,
	month = jun,
	eid = {arXiv:2406.03216},
	pages = {arXiv:2406.03216},
	doi = {10.48550/arXiv.2406.03216},
	archivePrefix = {arXiv},
	eprint = {2406.03216},
	primaryClass = {cs.LG},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2024arXiv240603216W},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@InProceedings{prefix-tuning,
	author    = {Roy, Anurag and Moulick, Riddhiman and Verma, Vinay and Ghosh, Saptarshi and Das, Abir},
	title     = {Convolutional Prompting meets Language Models for Continual Learning},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month     = {June},
	year      = {2024}
}

@InProceedings{cada-adapter-2025,
	author="Gao, Xinyuan
	and Dong, Songlin
	and He, Yuhang
	and Wang, Qiang
	and Gong, Yihong",
	editor="Leonardis, Ale{\v{s}}
	and Ricci, Elisa
	and Roth, Stefan
	and Russakovsky, Olga
	and Sattler, Torsten
	and Varol, G{\"u}l",
	title="Beyond Prompt Learning: Continual Adapter for Efficient Rehearsal-Free Continual Learning",
	booktitle="Computer Vision -- ECCV 2024",
	year="2025",
	publisher="Springer Nature Switzerland",
	address="Cham",
	pages="89--106",
	isbn="978-3-031-73013-9"
}
@inproceedings{
	st-adapter-2022,
	title={{ST}-Adapter: Parameter-Efficient Image-to-Video Transfer Learning},
	author={Junting Pan and Ziyi Lin and Xiatian Zhu and Jing Shao and Hongsheng Li},
	booktitle={Advances in Neural Information Processing Systems},
	editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	year={2022},
	url={https://openreview.net/forum?id=uRTW_PgXvc7}
}



@misc{dia-adapter-2025,
	title={Dynamic Integration of Task-Specific Adapters for Class Incremental Learning}, 
	author={Jiashuo Li and Shaokun Wang and Bo Qian and Yuhang He and Xing Wei and Qiang Wang and Yihong Gong},
	year={2025},
	eprint={2409.14983},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2409.14983}, 
}

@INPROCEEDINGS{ease-adapter-2024,
	author={Zhou, Da-Wei and Sun, Hai-Long and Ye, Han-Jia and Zhan, De-Chuan},
	booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	title={Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning}, 
	year={2024},
	volume={},
	number={},
	pages={23554-23564},
	doi={10.1109/CVPR52733.2024.02223}
}

@inproceedings{rapf-adapter-2024,
	author = {Huang, Linlan and Cao, Xusheng and Lu, Haori and Liu, Xialei},
	title = {Class-Incremental Learning with CLIP: Adaptive Representation Adjustment and Parameter Fusion},
	year = {2024},
	isbn = {978-3-031-72948-5},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	url = {https://doi.org/10.1007/978-3-031-72949-2_13},
	doi = {10.1007/978-3-031-72949-2_13},
	booktitle = {Computer Vision – ECCV 2024: 18th European Conference, Milan, Italy, September 29–October 4, 2024, Proceedings, Part LIV},
	pages = {214–231},
	numpages = {18},
	keywords = {Class-incremental Learning, Visual Language Model},
	location = {Milan, Italy}
}

@inproceedings{sema-2024,
	title={Self-Expansion of Pre-trained Models with Mixture of Adapters for Continual Learning},
	author={Huiyi Wang and Haodong Lu and Lina Yao and Dong Gong},
	booktitle={NeurIPS 2024 Workshop on Scalable Continual Learning for Lifelong Foundation Models},
	year={2024},
	url={https://openreview.net/forum?id=jHaOaTzLsy}
}


@inproceedings{ddas-2024,
	author = {Yu, Jiazuo and Zhuge, Yunzhi and Zhang, Lu and Hu, Ping and Wang, Dong and Lu, Huchuan and He, You},
	year = {2024},
	month = {06},
	pages = {23219-23230},
	title = {Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters},
	doi = {10.1109/CVPR52733.2024.02191}
}


@INPROCEEDINGS{distillation,
	author={Lu, Shuyun and Jiao, Jian and Wang, Lanxiao and Qiu, Heqian and Lin, Xingtao and Mei, Hefei and Li, Hongliang},
	booktitle={2024 IEEE International Conference on Image Processing (ICIP)}, 
	title={Video Class-Incremental Learning With Clip Based Transformer}, 
	year={2024},
	volume={},
	number={},
	pages={500-506},
	keywords={Learning systems;Continuing education;Incremental learning;Image recognition;Pipelines;Transformers;Decoding;class-incremental learning;action recognition;vision language pre-training;attention distillation;exemplar augment},
	doi={10.1109/ICIP51287.2024.10647787}}

















