% Generated by unsrt-fa.bst,  version: 0.9 (2015/05/09), for XePersian Package
% Authors: M.Amintoosi and M.Vahedi
\providecommand{\noopsort}[1]{}
\begin{thebibliography}{10}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{1}
Wang, Liyuan, Zhang, Xingxing, Su, Hang, and Zhu, Jun.
\newblock A comprehensive survey of continual learning: Theory, method and
  application.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{2}
Mai, Zheda, Li, Ruiwen, Jeong, Jihwan, Quispe, David, Kim, Hyunwoo, and Sanner,
  Scott.
\newblock Online continual learning in image classification: An empirical
  survey.
\newblock {\em Neurocomputing}, 469:28--51, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{3}
van~de Ven, Gido~M. and Tolias, Andreas~S.
\newblock Three scenarios for continual learning, 2019.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{4}
Churamani, Nikhil, Kara, Ozgur, and Gunes, Hatice.
\newblock { Domain-Incremental Continual Learning for Mitigating Bias in Facial
  Expression and Action Unit Recognition }.
\newblock {\em IEEE Transactions on Affective Computing}, 14(04):3191--3206,
  October 2023.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{5}
Ma, Jiawei, Tao, Xiaoyu, Ma, Jianxing, Hong, Xiaopeng, and Gong, Yihong.
\newblock Class incremental learning for video action classification.
\newblock  in {\em 2021 IEEE International Conference on Image Processing
  (ICIP)},  pp. 504--508, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{6}
Park, Jaeyoo, Kang, Minsoo, and Han, Bohyung.
\newblock Class-incremental learning for action recognition in videos.
\newblock  in {\em 2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)},  pp. 13678--13687, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{7}
Kirkpatrick, James, Pascanu, Razvan, Rabinowitz, Neil, Veness, Joel,
  Desjardins, Guillaume, Rusu, Andrei~A., Milan, Kieran, Quan, John, Ramalho,
  Tiago, Grabska-Barwinska, Agnieszka, Hassabis, Demis, Clopath, Claudia,
  Kumaran, Dharshan, and Hadsell, Raia.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the National Academy of Sciences},
  114(13):3521--3526, 2017.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{8}
Li, Zhizhong and Hoiem, Derek.
\newblock Learning without forgetting.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  40:2935--2947, 2016.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{9}
Shin, Hanul, Lee, Jung~Kwon, Kim, Jaehong, and Kim, Jiwon.
\newblock Continual learning with deep generative replay.
\newblock  in Guyon, I., Luxburg, U.~Von, Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R.,  eds. , {\em Advances in Neural
  Information Processing Systems},  vol.~30. Curran Associates, Inc., 2017.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{10}
Chaudhry, Arslan, Ranzato, Marc'Aurelio, Rohrbach, Marcus, and Elhoseiny,
  Mohamed.
\newblock Efficient lifelong learning with a-gem.
\newblock {\em ArXiv}, abs/1812.00420, 2018.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{11}
Rebuffi, Sylvestre-Alvise, Kolesnikov, Alexander, Sperl, Georg, and Lampert,
  Christoph~H.
\newblock icarl: Incremental classifier and representation learning.
\newblock  in {\em 2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 5533--5542, 2017.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{12}
Aljundi, Rahaf, Caccia, Lucas, Belilovsky, Eugene, Caccia, Massimo, Lin, Min,
  Charlin, Laurent, and Tuytelaars, Tinne.
\newblock Online continual learning with maximally interfered retrieval.
\newblock {\em ArXiv}, abs/1908.04742, 2019.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{13}
Minhas, Rashid, Mohammed, Abdul~Adeel, and Wu, Q. M.~Jonathan.
\newblock Incremental learning in human action recognition based on snippets.
\newblock {\em IEEE Transactions on Circuits and Systems for Video Technology},
  22(11):1529--1541, 2012.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{14}
Li, Tianjiao, Ke, Qiuhong, Rahmani, Hossein, Ho, Rui~En, Ding, Henghui, and
  Liu, Jun.
\newblock Else-net: Elastic semantic network for continual action recognition
  from skeleton data.
\newblock  in {\em 2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)},  pp. 13414--13423, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{15}
Cheng, Jian, Liu, Haijun, Wang, Feng, Li, Hongsheng, and Zhu, Ce.
\newblock Silhouette analysis for human action recognition based on supervised
  temporal t-sne and incremental learning.
\newblock {\em IEEE Transactions on Image Processing}, 24(10):3203--3217, 2015.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{16}
Parisi, German~I., Tani, Jun, Weber, Cornelius, and Wermter, Stefan.
\newblock Lifelong learning of human actions with deep neural network
  self-organization.
\newblock {\em Neural Networks}, 96:137--149, 2017.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{17}
Zhang, Jingyi, Huang, Jiaxing, Jin, Sheng, and Lu, Shijian.
\newblock Vision-language models for vision tasks: A survey.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  46(8):5625--5644, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{clip}
Radford, Alec, Kim, Jong~Wook, Hallacy, Chris, Ramesh, Aditya, Goh, Gabriel,
  Agarwal, Sandhini, Sastry, Girish, Askell, Amanda, Mishkin, Pamela, Clark,
  Jack, Krueger, Gretchen, and Sutskever, Ilya.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock  in {\em International Conference on Machine Learning}, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{flava}
Singh, Amanpreet, Hu, Ronghang, Goswami, Vedanuj, Couairon, Guillaume, Galuba,
  Wojciech, Rohrbach, Marcus, and Kiela, Douwe.
\newblock Flava: A foundational language and vision alignment model.
\newblock  in {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 15617--15629, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{glip}
Li, Liunian~Harold, Zhang, Pengchuan, Zhang, Haotian, Yang, Jianwei, Li,
  Chunyuan, Zhong, Yiwu, Wang, Lijuan, Yuan, Lu, Zhang, Lei, Hwang, Jenq-Neng,
  Chang, Kai-Wei, and Gao, Jianfeng.
\newblock Grounded language-image pre-training.
\newblock  in {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 10955--10965, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{actionclip}
Wang, Mengmeng, Xing, Jiazheng, and Liu, Yong.
\newblock Actionclip: A new paradigm for video action recognition.
\newblock {\em ArXiv}, abs/2109.08472, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{CoOp}
Zhou, Kaiyang, Yang, Jingkang, Loy, Chen~Change, and Liu, Ziwei.
\newblock Learning to prompt for vision-language models.
\newblock {\em International Journal of Computer Vision}, 130(9):2337–2348,
  July 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{CLIP-Adapter}
Gao, Peng, Geng, Shijie, Zhang, Renrui, Ma, Teli, Fang, Rongyao, Zhang,
  Yongfeng, Li, Hongsheng, and Qiao, Yu.
\newblock Clip-adapter: Better vision-language models with feature adapters.
\newblock {\em International Journal of Computer Vision}, 132(2):581--595, Feb
  2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{Wise-FT}
Wortsman, Mitchell, Ilharco, Gabriel, Kim, Jong~Wook, Li, Mike, Kornblith,
  Simon, Roelofs, Rebecca, Lopes, Raphael~Gontijo, Hajishirzi, Hannaneh,
  Farhadi, Ali, Namkoong, Hongseok, and Schmidt, Ludwig.
\newblock Robust fine-tuning of zero-shot models.
\newblock  in {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 7949--7961, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{open-vclip}
Weng, Zejia, Yang, Xitong, Li, Ang, Wu, Zuxuan, and Jiang, Yu-Gang.
\newblock Open-vclip: Transforming clip to an open-vocabulary video model via
  interpolated weight optimization.
\newblock  in {\em ICML}, 2023.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{ViLD}
Gu, Xiuye, Lin, Tsung-Yi, Kuo, Weicheng, and Cui, Yin.
\newblock Open-vocabulary detection via vision and language knowledge
  distillation.
\newblock {\em arXiv preprint arXiv:2104.13921}, 2021.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{CLIPSeg}
Lüddecke, Timo and Ecker, Alexander.
\newblock Image segmentation using text and image prompts.
\newblock  in {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 7076--7086, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{llm_continual}
Zheng, Junhao, Qiu, Shengjie, Shi, Chengming, and Ma, Qianli.
\newblock Towards lifelong learning of large language models: A survey.
\newblock {\em ACM Comput. Surv.}, 57(8), March 2025.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{replay_clip}
Garg, Saurabh, Farajtabar, Mehrdad, Pouransari, Hadi, Vemulapalli, Raviteja,
  Mehta, Sachin, Tuzel, Oncel, Shankar, Vaishaal, and Faghri, Fartash.
\newblock Tic-clip: Continual training of clip models.
\newblock  in {\em The Twelfth International Conference on Learning
  Representations (ICLR)}, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{distillation}
Lu, Shuyun, Jiao, Jian, Wang, Lanxiao, Qiu, Heqian, Lin, Xingtao, Mei, Hefei,
  and Li, Hongliang.
\newblock Video class-incremental learning with clip based transformer.
\newblock  in {\em 2024 IEEE International Conference on Image Processing
  (ICIP)},  pp. 500--506, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{l2p}
Wang, Zifeng, Zhang, Zizhao, Lee, Chen-Yu, Zhang, Han, Sun, Ruoxi, Ren, Xiaoqi,
  Su, Guolong, Perot, Vincent, Dy, Jennifer, and Pfister, Tomas.
\newblock Learning to prompt for continual learning.
\newblock  in {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 139--149, 2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{starprompt}
Menabue, Martin, Frascaroli, Emanuele, Boschini, Matteo, Sangineto, Enver,
  Bonicelli, Lorenzo, Porrello, Angelo, and Calderara, Simone.
\newblock Semantic residual prompts for continual learning.
\newblock  in Leonardis, Ale{\v{s}}, Ricci, Elisa, Roth, Stefan, Russakovsky,
  Olga, Sattler, Torsten, and Varol, G{\"u}l,  eds. , {\em Computer Vision --
  ECCV 2024},  pp. 1--18, Cham, 2025. Springer Nature Switzerland.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{dual-prompt}
Wang, Zifeng, Zhang, Zizhao, Ebrahimi, Sayna, Sun, Ruoxi, Zhang, Han, Lee,
  Chen-Yu, Ren, Xiaoqi, Su, Guolong, Perot, Vincent, Dy, Jennifer, and Pfister,
  Tomas.
\newblock Dualprompt: Complementary prompting for rehearsal-free continual
  learning.
\newblock  in {\em Computer Vision – ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23–27, 2022, Proceedings, Part XXVI},  p. 631–648,
  Berlin, Heidelberg, 2022. Springer-Verlag.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{h-prompts}
Zuo, Yukun, Yao, Hantao, Yu, Lu, Zhuang, Liansheng, and Xu, Changsheng.
\newblock Hierarchical prompts for rehearsal-free continual learning.
\newblock {\em ArXiv}, abs/2401.11544, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{instance_prompt}
Jung, Dahuin, Han, Dongyoon, Bang, Jihwan, and Song, Hwanjun.
\newblock Generating instance-level prompts for rehearsal-free continual
  learning.
\newblock  in {\em 2023 IEEE/CVF International Conference on Computer Vision
  (ICCV)},  pp. 11813--11823, 2023.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{ovor}
Huang, Wei-Cheng, Chen, Chun-Fu, and Hsu, Hsiang.
\newblock {OVOR}: Oneprompt with virtual outlier regularization for
  rehearsal-free class-incremental learning.
\newblock  in {\em The Twelfth International Conference on Learning
  Representations}, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{diki}
Tang, Longxiang, Tian, Zhuotao, Li, Kai, He, Chunming, Zhou, Hantao, Zhao,
  Hengshuang, Li, Xiu, and Jia, Jiaya.
\newblock Mind the interference: Retaining pre-trained knowledge in parameter
  efficient continual learning of vision-language models.
\newblock  in Leonardis, Ale{\v{s}}, Ricci, Elisa, Roth, Stefan, Russakovsky,
  Olga, Sattler, Torsten, and Varol, G{\"u}l,  eds. , {\em Computer Vision --
  ECCV 2024},  pp. 346--365, Cham, 2024. Springer Nature Switzerland.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{pivot}
Villa, Andrés, Alcázar, Juan~León, Alfarra, Motasem, Alhamoud, Kumail,
  Hurtado, Julio, Heilbron, Fabian~Caba, Soto, Alvaro, and Ghanem, Bernard.
\newblock Pivot: Prompting for video continual learning.
\newblock  in {\em 2023 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 24214--24223, 2023.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{clip-poolprompt}
Wang, Qiang, Du, Junlong, Yan, Ke, and Ding, Shouhong.
\newblock Seeing in flowing: Adapting clip for action recognition with motion
  prompts learning.
\newblock  in {\em Proceedings of the 31st ACM International Conference on
  Multimedia}, MM '23,  p. 5339–5347, New York, NY, USA, 2023. Association
  for Computing Machinery.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{vilt-clip}
Wang, Hao, Liu, Fang, Jiao, Licheng, Wang, Jiahao, Hao, Zehua, Li, Shuo, Li,
  Lingling, Chen, Puhua, and Liu, Xu.
\newblock Vilt-clip: Video and language tuning clip with multimodal prompt
  learning and scenario-guided optimization.
\newblock {\em Proceedings of the AAAI Conference on Artificial Intelligence},
  38(6):5390--5400, Mar. 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{prefix-tuning}
Roy, Anurag, Moulick, Riddhiman, Verma, Vinay, Ghosh, Saptarshi, and Das, Abir.
\newblock Convolutional prompting meets language models for continual learning.
\newblock  in {\em Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{lora}
{Wistuba}, Martin, {Teja Sivaprasad}, Prabhu, {Balles}, Lukas, and {Zappella},
  Giovanni.
\newblock {Choice of PEFT Technique in Continual Learning: Prompt Tuning is Not
  All You Need}.
\newblock {\em arXiv e-prints},  p. arXiv:2406.03216, June 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{dia-adapter-2025}
Li, Jiashuo, Wang, Shaokun, Qian, Bo, He, Yuhang, Wei, Xing, Wang, Qiang, and
  Gong, Yihong.
\newblock Dynamic integration of task-specific adapters for class incremental
  learning, 2025.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{ease-adapter-2024}
Zhou, Da-Wei, Sun, Hai-Long, Ye, Han-Jia, and Zhan, De-Chuan.
\newblock Expandable subspace ensemble for pre-trained model-based
  class-incremental learning.
\newblock  in {\em 2024 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)},  pp. 23554--23564, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{cada-adapter-2025}
Gao, Xinyuan, Dong, Songlin, He, Yuhang, Wang, Qiang, and Gong, Yihong.
\newblock Beyond prompt learning: Continual adapter for efficient
  rehearsal-free continual learning.
\newblock  in Leonardis, Ale{\v{s}}, Ricci, Elisa, Roth, Stefan, Russakovsky,
  Olga, Sattler, Torsten, and Varol, G{\"u}l,  eds. , {\em Computer Vision --
  ECCV 2024},  pp. 89--106, Cham, 2025. Springer Nature Switzerland.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{rapf-adapter-2024}
Huang, Linlan, Cao, Xusheng, Lu, Haori, and Liu, Xialei.
\newblock Class-incremental learning with clip: Adaptive representation
  adjustment and parameter fusion.
\newblock  in {\em Computer Vision – ECCV 2024: 18th European Conference,
  Milan, Italy, September 29–October 4, 2024, Proceedings, Part LIV},  p.
  214–231, Berlin, Heidelberg, 2024. Springer-Verlag.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{st-adapter-2022}
Pan, Junting, Lin, Ziyi, Zhu, Xiatian, Shao, Jing, and Li, Hongsheng.
\newblock {ST}-adapter: Parameter-efficient image-to-video transfer learning.
\newblock  in Oh, Alice~H., Agarwal, Alekh, Belgrave, Danielle, and Cho,
  Kyunghyun,  eds. , {\em Advances in Neural Information Processing Systems},
  2022.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{sema-2024}
Wang, Huiyi, Lu, Haodong, Yao, Lina, and Gong, Dong.
\newblock Self-expansion of pre-trained models with mixture of adapters for
  continual learning.
\newblock  in {\em NeurIPS 2024 Workshop on Scalable Continual Learning for
  Lifelong Foundation Models}, 2024.

\end{LTRbibitems}

\begin{LTRbibitems}
\resetlatinfont
\bibitem{ddas-2024}
Yu, Jiazuo, Zhuge, Yunzhi, Zhang, Lu, Hu, Ping, Wang, Dong, Lu, Huchuan, and
  He, You.
\newblock Boosting continual learning of vision-language models via
  mixture-of-experts adapters.
\newblock  pp. 23219--23230, 06 2024.

\end{LTRbibitems}

\end{thebibliography}
